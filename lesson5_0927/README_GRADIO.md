# 🤖 AI 專業翻譯助手 - Gradio 介面

## 📋 專案簡介

這是一個基於 LangChain 和 Ollama 的智能翻譯工具，現在配備了現代化的 Gradio 網頁介面，讓您能夠輕鬆進行多語言專業翻譯。

## ✨ 主要功能

### 🌍 多語言支援
- **支援語言**: 繁體中文、簡體中文、英文、日文、韓文、法文、德文、西班牙文、義大利文、俄文
- **雙向翻譯**: 支援任意兩種語言之間的翻譯

### 🎯 專業領域翻譯
- **一般**: 日常對話和通用文本
- **商業**: 商業報告、合約、財務文件
- **科技**: 技術文件、程式碼註解、API 文檔
- **醫療**: 醫療報告、藥品說明、診斷書
- **法律**: 法律條文、合約、訴訟文件
- **文學**: 小說、詩歌、文學作品
- **新聞**: 新聞報導、時事評論
- **學術**: 研究論文、學術報告
- **技術文件**: 產品手冊、操作指南
- **行銷**: 廣告文案、行銷材料

### 🎨 現代化介面特色
- **響應式設計**: 適配各種螢幕尺寸
- **直觀操作**: 簡潔明瞭的使用者介面
- **即時翻譯**: 快速獲得翻譯結果
- **範例支援**: 內建多種翻譯範例
- **狀態顯示**: 即時顯示翻譯進度

## 🚀 快速開始

### 1. 環境準備
```bash
# 確保已安裝 Ollama 並下載模型
ollama pull gpt-oss:20b

# 安裝 Python 依賴
pip install -r requirements.txt
```

### 2. 啟動應用程式
```bash
python gradio_translator.py
```

### 3. 使用介面
- 程式啟動後會自動在瀏覽器中開啟介面
- 本地訪問地址：`http://127.0.0.1:7860`
- 公開連結會自動生成，方便分享給他人使用

## 💡 使用指南

### 基本翻譯流程
1. **選擇語言**: 在「源語言」和「目標語言」下拉選單中選擇對應語言
2. **選擇領域**: 根據文本內容選擇適當的專業領域
3. **輸入文本**: 在文本框中輸入要翻譯的內容
4. **開始翻譯**: 點擊「🚀 開始翻譯」按鈕
5. **查看結果**: 翻譯結果會顯示在右側的結果區域

### 進階功能
- **範例使用**: 點擊下方的範例可以快速填入測試內容
- **清除功能**: 使用「🗑️ 清除」按鈕快速清空所有內容
- **複製結果**: 使用「📋 複製結果」按鈕複製翻譯結果

## 🔧 技術架構

### 核心組件
- **LangChain**: 提供 AI 模型整合框架
- **Ollama**: 本地 AI 模型運行環境
- **Gradio**: 現代化網頁介面框架
- **GPT-OSS 20B**: 大型語言模型

### 系統要求
- **Python**: 3.8 或更高版本
- **記憶體**: 建議 16GB 以上（運行 20B 模型）
- **儲存空間**: 至少 20GB 可用空間
- **網路**: 初始下載模型時需要網路連線

## 🎯 使用場景

### 個人使用
- **學習語言**: 翻譯外語學習材料
- **閱讀外文**: 翻譯外語文章和書籍
- **工作文件**: 翻譯商務郵件和報告

### 專業用途
- **內容創作**: 多語言內容製作
- **技術文檔**: 程式碼和技術文件翻譯
- **學術研究**: 研究論文和文獻翻譯
- **商業應用**: 國際化產品和服務

## 🛠️ 自定義設定

### 修改模型
如需使用不同的 Ollama 模型，請修改 `gradio_translator.py` 中的模型名稱：
```python
model = OllamaLLM(model="your-model-name")
```

### 添加語言
在 `languages` 列表中添加新語言：
```python
languages = [
    "繁體中文", "簡體中文", "英文", "日文", "韓文",
    "法文", "德文", "西班牙文", "義大利文", "俄文",
    "新語言"  # 添加新語言
]
```

### 自定義領域
在 `domains` 列表中添加新的專業領域：
```python
domains = [
    "一般", "商業", "科技", "醫療", "法律",
    "文學", "新聞", "學術", "技術文件", "行銷",
    "新領域"  # 添加新領域
]
```

## 📞 技術支援

### 常見問題
1. **模型載入失敗**: 確保 Ollama 已正確安裝並下載了 `gpt-oss:20b` 模型
2. **翻譯速度慢**: 大型模型需要較多計算資源，建議使用 GPU 加速
3. **介面無法開啟**: 檢查端口 7860 是否被其他程式佔用

### 效能優化
- 使用 GPU 版本的 Ollama 以提升翻譯速度
- 調整批處理大小以平衡速度和記憶體使用
- 考慮使用較小的模型以提升響應速度

## 📄 授權資訊

本專案基於開源軟體構建，遵循相應的開源授權條款。

---

**享受您的 AI 翻譯體驗！** 🎉

